{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Food Identification mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from shutil import copytree, rmtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def dataset_mini(food_list, src, dest):\n",
    "    if os.path.exists(dest):\n",
    "        rmtree(dest)\n",
    "    os.makedirs(dest)\n",
    "    for food_item in food_list :\n",
    "        print(\"Copying images into\",food_item)\n",
    "        copytree(os.path.join(src,food_item), os.path.join(dest,food_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "food_list = ['donuts','pizza','samosa']\n",
    "src_train = '../Data/Train'\n",
    "dest_train = '../Data/Train_mini'\n",
    "src_test = '../Data/Test'\n",
    "dest_test = '../Data/Test_mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train data folder with new classes\n",
      "Copying images into donuts\n",
      "Copying images into pizza\n",
      "Copying images into samosa\n",
      "Creating test data folder with new classes\n",
      "Copying images into donuts\n",
      "Copying images into pizza\n",
      "Copying images into samosa\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating train data folder with new classes\")\n",
    "dataset_mini(food_list, src_train, dest_train)\n",
    "print(\"Creating test data folder with new classes\")\n",
    "dataset_mini(food_list, src_test, dest_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2250 images belonging to 3 classes.\n",
      "Found 750 images belonging to 3 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-25 16:46:47.904709: W tensorflow/core/framework/op_kernel.cc:1755] Invalid argument: ValueError: callback pyfunc_2 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/data-science/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_2 is not found\n",
      "\n",
      "\n",
      "2021-09-25 16:46:47.904784: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_2 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/data-science/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_2 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "2021-09-25 16:46:49.055784: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - ETA: 0s - loss: 0.9930 - accuracy: 0.5555"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-25 16:48:46.842527: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 129s 904ms/step - loss: 0.9930 - accuracy: 0.5555 - val_loss: 0.6456 - val_accuracy: 0.8818\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.64560, saving model to best_model_3class.hdf5\n",
      "Epoch 2/30\n",
      "140/140 [==============================] - 127s 906ms/step - loss: 0.6638 - accuracy: 0.8048 - val_loss: 0.3898 - val_accuracy: 0.9470\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.64560 to 0.38982, saving model to best_model_3class.hdf5\n",
      "Epoch 3/30\n",
      "140/140 [==============================] - 127s 909ms/step - loss: 0.4802 - accuracy: 0.8675 - val_loss: 0.2779 - val_accuracy: 0.9511\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.38982 to 0.27789, saving model to best_model_3class.hdf5\n",
      "Epoch 4/30\n",
      "140/140 [==============================] - 125s 892ms/step - loss: 0.3821 - accuracy: 0.8926 - val_loss: 0.2149 - val_accuracy: 0.9606\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.27789 to 0.21494, saving model to best_model_3class.hdf5\n",
      "Epoch 5/30\n",
      "140/140 [==============================] - 127s 907ms/step - loss: 0.3398 - accuracy: 0.8993 - val_loss: 0.1844 - val_accuracy: 0.9647\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.21494 to 0.18438, saving model to best_model_3class.hdf5\n",
      "Epoch 6/30\n",
      "140/140 [==============================] - 126s 900ms/step - loss: 0.3011 - accuracy: 0.9172 - val_loss: 0.1606 - val_accuracy: 0.9688\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.18438 to 0.16056, saving model to best_model_3class.hdf5\n",
      "Epoch 7/30\n",
      "140/140 [==============================] - 123s 875ms/step - loss: 0.2446 - accuracy: 0.9284 - val_loss: 0.1418 - val_accuracy: 0.9755\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.16056 to 0.14177, saving model to best_model_3class.hdf5\n",
      "Epoch 8/30\n",
      "140/140 [==============================] - 122s 874ms/step - loss: 0.2571 - accuracy: 0.9226 - val_loss: 0.1328 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.14177 to 0.13281, saving model to best_model_3class.hdf5\n",
      "Epoch 9/30\n",
      "140/140 [==============================] - 122s 873ms/step - loss: 0.2342 - accuracy: 0.9261 - val_loss: 0.1215 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.13281 to 0.12152, saving model to best_model_3class.hdf5\n",
      "Epoch 10/30\n",
      "140/140 [==============================] - 122s 873ms/step - loss: 0.2189 - accuracy: 0.9329 - val_loss: 0.1167 - val_accuracy: 0.9796\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.12152 to 0.11670, saving model to best_model_3class.hdf5\n",
      "Epoch 11/30\n",
      "140/140 [==============================] - 122s 873ms/step - loss: 0.2072 - accuracy: 0.9391 - val_loss: 0.1095 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.11670 to 0.10947, saving model to best_model_3class.hdf5\n",
      "Epoch 12/30\n",
      "140/140 [==============================] - 123s 879ms/step - loss: 0.1760 - accuracy: 0.9512 - val_loss: 0.1074 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.10947 to 0.10736, saving model to best_model_3class.hdf5\n",
      "Epoch 13/30\n",
      "140/140 [==============================] - 123s 876ms/step - loss: 0.1766 - accuracy: 0.9499 - val_loss: 0.1032 - val_accuracy: 0.9796\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.10736 to 0.10316, saving model to best_model_3class.hdf5\n",
      "Epoch 14/30\n",
      "140/140 [==============================] - 123s 880ms/step - loss: 0.1624 - accuracy: 0.9566 - val_loss: 0.0992 - val_accuracy: 0.9796\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.10316 to 0.09924, saving model to best_model_3class.hdf5\n",
      "Epoch 15/30\n",
      "140/140 [==============================] - 123s 877ms/step - loss: 0.1714 - accuracy: 0.9494 - val_loss: 0.0954 - val_accuracy: 0.9783\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.09924 to 0.09538, saving model to best_model_3class.hdf5\n",
      "Epoch 16/30\n",
      "140/140 [==============================] - 124s 881ms/step - loss: 0.1427 - accuracy: 0.9638 - val_loss: 0.0904 - val_accuracy: 0.9810\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.09538 to 0.09036, saving model to best_model_3class.hdf5\n",
      "Epoch 17/30\n",
      "140/140 [==============================] - 126s 896ms/step - loss: 0.1339 - accuracy: 0.9691 - val_loss: 0.0882 - val_accuracy: 0.9796\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.09036 to 0.08821, saving model to best_model_3class.hdf5\n",
      "Epoch 18/30\n",
      "140/140 [==============================] - 123s 879ms/step - loss: 0.1353 - accuracy: 0.9633 - val_loss: 0.0811 - val_accuracy: 0.9837\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.08821 to 0.08109, saving model to best_model_3class.hdf5\n",
      "Epoch 19/30\n",
      "140/140 [==============================] - 124s 882ms/step - loss: 0.1419 - accuracy: 0.9651 - val_loss: 0.0863 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.08109\n",
      "Epoch 20/30\n",
      "140/140 [==============================] - 127s 906ms/step - loss: 0.1174 - accuracy: 0.9714 - val_loss: 0.0862 - val_accuracy: 0.9837\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.08109\n",
      "Epoch 21/30\n",
      "140/140 [==============================] - 123s 876ms/step - loss: 0.1257 - accuracy: 0.9682 - val_loss: 0.0830 - val_accuracy: 0.9823\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.08109\n",
      "Epoch 22/30\n",
      "140/140 [==============================] - 123s 876ms/step - loss: 0.1142 - accuracy: 0.9700 - val_loss: 0.0837 - val_accuracy: 0.9837\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.08109\n",
      "Epoch 23/30\n",
      "140/140 [==============================] - 123s 881ms/step - loss: 0.1163 - accuracy: 0.9722 - val_loss: 0.0790 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.08109 to 0.07902, saving model to best_model_3class.hdf5\n",
      "Epoch 24/30\n",
      "140/140 [==============================] - 123s 879ms/step - loss: 0.1017 - accuracy: 0.9749 - val_loss: 0.0794 - val_accuracy: 0.9837\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.07902\n",
      "Epoch 25/30\n",
      "140/140 [==============================] - 125s 891ms/step - loss: 0.1088 - accuracy: 0.9754 - val_loss: 0.0797 - val_accuracy: 0.9864\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.07902\n",
      "Epoch 26/30\n",
      "140/140 [==============================] - 125s 895ms/step - loss: 0.1002 - accuracy: 0.9816 - val_loss: 0.0795 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.07902\n",
      "Epoch 27/30\n",
      "140/140 [==============================] - 125s 891ms/step - loss: 0.0801 - accuracy: 0.9866 - val_loss: 0.0768 - val_accuracy: 0.9864\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.07902 to 0.07683, saving model to best_model_3class.hdf5\n",
      "Epoch 28/30\n",
      "140/140 [==============================] - 123s 875ms/step - loss: 0.1019 - accuracy: 0.9772 - val_loss: 0.0787 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.07683\n",
      "Epoch 29/30\n",
      "140/140 [==============================] - 124s 883ms/step - loss: 0.0902 - accuracy: 0.9830 - val_loss: 0.0796 - val_accuracy: 0.9864\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.07683\n",
      "Epoch 30/30\n",
      "140/140 [==============================] - 123s 876ms/step - loss: 0.0904 - accuracy: 0.9808 - val_loss: 0.0767 - val_accuracy: 0.9864\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.07683 to 0.07668, saving model to best_model_3class.hdf5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "K.clear_session()\n",
    "n_classes = 3\n",
    "img_width, img_height = 299, 299\n",
    "train_data_dir = dest_train\n",
    "validation_data_dir = dest_test\n",
    "nb_train_samples = 2250\n",
    "nb_validation_samples = 750\n",
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "\n",
    "inception = InceptionV3(weights='imagenet', include_top=False)\n",
    "x = inception.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128,activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "predictions = Dense(3,kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inception.input, outputs=predictions)\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath='best_model_3class.hdf5', verbose=1, save_best_only=True)\n",
    "csv_logger = CSVLogger('history_3class.log')\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch = nb_train_samples // batch_size,\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=nb_validation_samples // batch_size,\n",
    "                              epochs=30,\n",
    "                              verbose=1,\n",
    "                              callbacks=[csv_logger, checkpointer])\n",
    "\n",
    "model.save('model_trained_3class.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "{'donuts': 0, 'pizza': 1, 'samosa': 2}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_map_3 = train_generator.class_indices\n",
    "class_map_3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-25 20:57:23.807119: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-09-25 20:57:23.807206: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-25 20:57:28.655663: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/qj/ky4j5wv51qn6q4zgqgbxydbw0000gn/T/tmpa257hg3o/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-25 20:57:35.675098: I tensorflow/core/grappler/devices.cc:78] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2021-09-25 20:57:35.675161: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2021-09-25 20:57:35.675308: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-09-25 20:57:35.675322: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2021-09-25 20:57:35.675439: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-09-25 20:57:35.682554: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-25 20:57:35.682575: W tensorflow/core/grappler/optimizers/meta_optimizer.cc:605] User's config has been changed based on plugin's config.\n",
      "2021-09-25 20:57:35.682581: W tensorflow/core/grappler/optimizers/meta_optimizer.cc:606] \n",
      "Config of optimizers\t\tUser's config\tPlugin's config\tFinal config(User & Plugin)\n",
      "disable_model_pruning\t\t1\t\t0\t\t1\n",
      "function_optimization           1\t\t1\t\t1\n",
      "\n",
      "2021-09-25 20:57:35.687353: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1144] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "  PluggableGraphOptimizer: Graph size after: 1190 nodes (0), 1604 edges (0), time = 1.077ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.811ms.\n",
      "  PluggableGraphOptimizer: Graph size after: 1190 nodes (0), 1604 edges (0), time = 1.052ms.\n",
      "\n",
      "2021-09-25 20:57:37.125472: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:345] Ignored output_format.\n",
      "2021-09-25 20:57:37.125486: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:348] Ignored drop_control_dependency.\n",
      "2021-09-25 20:57:37.194349: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2021-09-25 20:57:37.205342: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-09-25 20:57:37.205359: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('../Model/model_trained_3class.hdf5', compile=False)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('../Model/model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}